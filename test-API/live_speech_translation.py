import os
import time
import azure.cognitiveservices.speech as speechsdk
from dotenv import load_dotenv

load_dotenv()

def start_wedding_translator():
    # 1. Configuration de base
    # Note: Il est souvent plus simple d'utiliser 'region' plutÃ´t que 'endpoint'
    speech_key = os.environ.get('SPEECH_KEY')
    service_region = os.environ.get('SPEECH_REGION')

    if not speech_key or not service_region:
        print("âŒ Erreur: ClÃ©s manquantes dans le fichier .env")
        return

    translation_config = speechsdk.translation.SpeechTranslationConfig(
        subscription=speech_key, 
        region=service_region
    )

    # 2. Configuration de la traduction
    # On ajoute les deux langues cibles.
    # Azure traduira vers les DEUX, nous afficherons celle qui nous intÃ©resse.
    translation_config.add_target_language("fr")
    translation_config.add_target_language("es")

    # 3. Configuration de la dÃ©tection automatique de langue (Source)
    # On prÃ©cise Ã  Azure de s'attendre soit Ã  du FranÃ§ais (France), soit Ã  de l'Espagnol (Mexique)
    auto_detect_config = speechsdk.languageconfig.AutoDetectSourceLanguageConfig(
        languages=["fr-FR", "es-MX"]
    )

    # 4. Configuration Audio
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)

    # 5. CrÃ©ation du Recognizer
    recognizer = speechsdk.translation.TranslationRecognizer(
        translation_config=translation_config, 
        audio_config=audio_config,
        auto_detect_source_language_config=auto_detect_config
    )

    # --- GESTION DES Ã‰VÃ‰NEMENTS (CALLBACKS) ---

    def result_callback(evt):
        """AppelÃ© quand une phrase est TERMINÃ‰E et TRADUITE"""
        if evt.result.reason == speechsdk.ResultReason.TranslatedSpeech:
            
            # DÃ©tection de la langue parlÃ©e (ex: 'fr-FR' ou 'es-MX')
            detected_lang = evt.result.properties[speechsdk.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult]
            
            print(f"\nğŸ—£ï¸  Langue dÃ©tectÃ©e: {detected_lang}")
            print(f"Original: {evt.result.text}")

            # Logique d'affichage croisÃ©
            if "fr" in detected_lang:
                # Si on parle franÃ§ais, on veut voir l'espagnol
                print(f"ğŸ‡²ğŸ‡½ Traduction: {evt.result.translations['es']}")
            elif "es" in detected_lang:
                # Si on parle espagnol, on veut voir le franÃ§ais
                print(f"ğŸ‡«ğŸ‡· Traduction: {evt.result.translations['fr']}")
            
            print("-" * 30)

    def recognizing_callback(evt):
        """AppelÃ© plusieurs fois par seconde pendant que la personne parle"""
        if evt.result.reason == speechsdk.ResultReason.TranslatingSpeech:
            
            # 1. RÃ©cupÃ©ration de la langue dÃ©tectÃ©e (peut Ãªtre instable au tout dÃ©but)
            auto_detect_source_language_result = evt.result.properties[speechsdk.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult]
            
            # 2. Logique d'affichage croisÃ© (identique Ã  tout Ã  l'heure)
            target_text = ""
            
            if "fr" in auto_detect_source_language_result:
                # L'orateur parle FranÃ§ais -> On prÃ©pare l'Espagnol
                target_text = evt.result.translations['es']
                prefix = "ğŸ‡²ğŸ‡½ (En cours...)"
                
            elif "es" in auto_detect_source_language_result:
                # L'orateur parle Espagnol -> On prÃ©pare le FranÃ§ais
                target_text = evt.result.translations['fr']
                prefix = "ğŸ‡«ğŸ‡· (En cours...)"
            else:
                # Langue pas encore identifiÃ©e (les premiÃ¨res millisecondes)
                prefix = "â³ (...)"
                target_text = "..."

            # 3. Affichage dynamique (On Ã©crase la ligne actuelle)
            # \r ramÃ¨ne le curseur au dÃ©but de la ligne sans sauter de ligne
            # ljust(100) ajoute des espaces vides pour effacer les traces de phrases prÃ©cÃ©dentes plus longues
            print(f"\r{prefix} : {target_text}".ljust(100), end="", flush=True)

    # Connexion des Ã©vÃ©nements
    recognizer.recognized.connect(result_callback)
    recognizer.recognizing.connect(recognizing_callback)

    # --- BOUCLE PRINCIPALE ---
    
    print("--------------------------------------------------")
    print("ğŸ™ï¸  WEDDING TRANSLATOR (FR <-> MX)")
    print("Appuyez sur EntrÃ©e pour DÃ‰MARRER l'Ã©coute.")
    print("Appuyez sur Ctrl+C pour QUITTER complÃ¨tement.")
    print("--------------------------------------------------")

    try:
        input() # Attente utilisateur
        print("ğŸ”´ Ã‰coute en cours... (Parlez maintenant)")
        
        # DÃ©marrage de la reconnaissance continue
        recognizer.start_continuous_recognition()

        while True:
            # On utilise une boucle simple ici pour maintenir le script en vie
            # Dans une vraie app graphique, ce serait gÃ©rÃ© par la fenÃªtre
            user_input = input("Appuyez sur EntrÃ©e pour mettre en PAUSE ou 'q' pour quitter: ")
            
            if user_input.lower() == 'q':
                break
            
            print("â¸ï¸  Pause... (Ã‰conomie API)")
            recognizer.stop_continuous_recognition()
            
            input("Appuyez sur EntrÃ©e pour REPRENDRE...")
            print("ğŸ”´ Reprise de l'Ã©coute...")
            recognizer.start_continuous_recognition()

    except KeyboardInterrupt:
        pass
    finally:
        recognizer.stop_continuous_recognition()
        print("\nArrÃªt du programme.")

if __name__ == "__main__":
    start_wedding_translator()